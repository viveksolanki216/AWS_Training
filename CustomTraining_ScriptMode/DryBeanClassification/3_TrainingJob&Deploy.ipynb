{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3c29b0-9dca-4847-9f76-34cea037a72f",
   "metadata": {},
   "source": [
    "# Amazon Sagemaker AI : Dry Bean Classification Problem\n",
    "You will learn\n",
    " - Using Sagemaker AI to train the model in notebook itself.\n",
    " - AWS -> Sagemaker AI ->  Create a Domain -> Open Studio -> Creating a Jupyter Lab Space with a machine\n",
    " - In Jupyter Lab Space create a notebook -> load dataset -> and train model in notebook itself\n",
    "\n",
    "references: https://www.datacamp.com/tutorial/aws-sagemaker-tutorial\n",
    "\n",
    "references: https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-python-sdk/scikit_learn_iris/scikit_learn_estimator_example_with_batch_transform_outputs.html#upload_data\n",
    "\n",
    "## Issues Arised:\n",
    "### Couldn't access/read files from user/new created buckets.\n",
    "Reason being S3 read access was not allowed for the role that is executing the code.\n",
    "- Role: Role is kind of a hat that a user assumes to execute a task. It contains all the necessary permissions to resources needed to execute the task.\n",
    "- Policy: each role has a policy attached as a json document, which we can edit to give necessary permissions or there are pre-defined policies that can be used.\n",
    "i.e. for this issue, just display the role using `get_execution_role(sagemaker_session=sagemaker.Session())`, and attach the aws managed policy to \"AmazonS3FullAccess\" to the role. This will give access to all the buckets for the current user. Or if you want to give\n",
    "access to a selected bucket either edit the policy attached to the role or create a custom managed policy.\n",
    "\n",
    "\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"s3:ListBucket\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Resource\": [\n",
    "\t\t\t\t\"arn:aws:s3:::SageMaker\",\n",
    "\t\t\t\t\"*\"\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"s3:GetObject\",\n",
    "\t\t\t\t\"s3:PutObject\",\n",
    "\t\t\t\t\"s3:DeleteObject\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Resource\": [\n",
    "\t\t\t\t\"arn:aws:s3:::SageMaker/*\",\n",
    "                \"arn:aws:s3:::{bucket_name}/*\",\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "d1840b12-0629-492e-9d9f-53c1ec04029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (2.240.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.243.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.36.23)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.115.11)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.25)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.23 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.36.23)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (0.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.23.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (0.46.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.243.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.240.0\n",
      "    Uninstalling sagemaker-2.240.0:\n",
      "      Successfully uninstalled sagemaker-2.240.0\n",
      "Successfully installed sagemaker-2.243.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "a0fd389b-2963-404b-84eb-1e4eb6915dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import boto3      # aws python sdk to access other qws services. \n",
    "import sagemaker  # sagemaker python sdk to access other sagemaker services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_state": "idle",
   "id": "fdc81fc4-3dd9-414e-9bea-7714dc447d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::205930620783:role/service-role/AmazonSageMaker-ExecutionRole-20250401T145997\n",
      "us-east-1\n",
      "sagemaker-us-east-1-205930620783\n"
     ]
    }
   ],
   "source": [
    "#Session: Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "sess = sagemaker.Session()           # Sagemaker Python SDK to interact with sagemaker service\n",
    "ROLE = get_execution_role(sagemaker_session=sess)\n",
    "BUCKET = sess.default_bucket()\n",
    "REGION = sess.boto_session.region_name\n",
    "print(ROLE)\n",
    "print(REGION)\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "c30bc016-d250-4389-9ec4-40b0e8e2b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::205930620783:role/service-role/AmazonSageMaker-ExecutionRole-20250401T145997\n",
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\") # AWS Python SDK to interact with AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_state": "idle",
   "id": "e37f1c15-e0e0-44b5-ac1d-ae5a7f4d74e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dry-bean-classification-problem/', 'dry-bean-classification-problem/dataset/', 'dry-bean-classification-problem/dataset/Dry_Bean_Dataset.csv', 'dry-bean-classification-problem/dataset/dry-bean-test.csv', 'dry-bean-classification-problem/dataset/dry-bean-train.csv', 'dry-bean-classification-problem/dataset/models/sagemaker-scikit-learn-2025-04-02-03-42-46-014/debug-output/training_job_end.ts', 'dry-bean-classification-problem/dataset/models/sagemaker-scikit-learn-2025-04-02-03-42-46-014/profiler-output/framework/training_job_end.ts', 'dry-bean-classification-problem/dataset/models/sagemaker-scikit-learn-2025-04-02-03-42-46-014/profiler-output/system/incremental/2025040203/1743565380.algo-1.json', 'dry-bean-classification-problem/dataset/models/sagemaker-scikit-learn-2025-04-02-03-42-46-014/profiler-output/system/incremental/2025040203/1743565440.algo-1.json', 'dry-bean-classification-problem/dataset/models/sagemaker-scikit-learn-2025-04-02-03-42-46-014/profiler-output/system/training_job_end.ts', 'dry-bean-classification-problem/models/']\n",
      "Bucket Items\n",
      "['dataset/', 'dataset/Dry_Bean_Dataset.csv', 'dataset/dry-bean-test.csv', 'dataset/dry-bean-train.csv']\n"
     ]
    }
   ],
   "source": [
    "# If we did not edit the policy for the role, i.e. specified bucket in the \n",
    "print(sess.list_s3_files(\"sagemaker-us-east-1-205930620783\", \"dry-bean-classification-problem/\"))\n",
    "print(\"Bucket Items\")\n",
    "print(sess.list_s3_files(\"dry-bean-classification-problem-usa-east1\", \"dataset/\"))\n",
    "\n",
    "# Only able to read and write in the default created bucket\n",
    "#BUCKET_NAME = \"sagemaker-us-east-1-205930620783\"\n",
    "BUCKET_NAME = \"dry-bean-classification-problem-usa-east1\"\n",
    "BUCKET_URI = f\"s3://{BUCKET_NAME}\"\n",
    "\n",
    "DATASET_PREFIX = \"dataset\"\n",
    "MODELS_PREFIX = \"models\"\n",
    "\n",
    "TARGET_VAR = \"Class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc92b1-651a-433d-b39b-3ca372040519",
   "metadata": {},
   "source": [
    "### Read train and test data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "72e7682b-b2a7-40d6-a13a-3cad0c8f6305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{BUCKET_URI}/{DATASET_PREFIX}/dry-bean-train.csv')\n",
    "df_test = pd.read_csv(f'{BUCKET_URI}/{DATASET_PREFIX}/dry-bean-test.csv')\n",
    "# You can write file to s3, instead of uploading the data\n",
    "#df_test.to_csv(f'{BUCKET_URI}/{DATASET_PREFIX}/dry-bean-test2.csv')\n",
    "X_train, y_train = df_train.drop(['Class'], axis=1).values, df_train['Class'].values\n",
    "X_test, y_test = df_test.drop(['Class'], axis=1).values, df_test['Class'].values\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71fd3-7cd9-437a-ad3f-f5af511009ec",
   "metadata": {},
   "source": [
    "### Write a python script in the current dir to give run it as a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "fbf0c3e8-bda5-4add-b66e-ca48d63f8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import boto3\n",
    "import tempfile\n",
    "import numpy as np\n",
    "# Create a python script that takes the arguments from the command line for hyperparameters,\n",
    "# trains the model\n",
    "# and store the model.\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--max-depth\", type=int, default=7)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=10)\n",
    "    parser.add_argument(\"--model-dir\", type=str)\n",
    "    parser.add_argument(\"--model-filename\", type=str)\n",
    "    parser.add_argument(\"--train-dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test-dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"california_housing_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"california_housing_test.csv\")\n",
    "    parser.add_argument(\"--features\", type=str)\n",
    "    parser.add_argument(\"--target\", type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print('reading data')\n",
    "    train_data_path = os.path.join(args.train_dir, args.train_file)\n",
    "    print('train_data_path:', train_data_path)\n",
    "    test_data_path = os.path.join(args.test_dir, args.test_file)\n",
    "    print('test_data_path:', test_data_path)\n",
    "\n",
    "    df_train = pd.read_csv(train_data_path)\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "    X_train, y_train = df_train[args.features.split()], df_train[args.target]\n",
    "    X_test, y_test = df_test[args.features.split()], df_test[args.target]\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model_rf = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_depth=args.max_depth,\n",
    "        min_samples_leaf=args.min_samples_leaf,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = model_rf.predict(X_test)\n",
    "    y_train_pred = model_rf.predict(X_train)\n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    bal_acc_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    bal_acc_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "    print(f\"Train balanced accuracy: {bal_acc_train:.3f}\")\n",
    "    print(f\"Test balanced accuracy: {bal_acc_test:.3f}\")\n",
    "    \n",
    "    # presist the model i.e. save it\n",
    "    #path = f\"{args.model_dir}model.joblib\"\n",
    "    #print(path)\n",
    "    #joblib.dump(model_rf, path) # this gives error when directly dumping it on s3 bucket.\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # AWS Python SDK to interact with AWS services\n",
    "    with tempfile.TemporaryFile() as fp:\n",
    "             joblib.dump(model_rf, fp)\n",
    "             fp.seek(0)\n",
    "             print(f'model saved to s3 bucket {args.model_dir} at {args.model_filename}')\n",
    "             s3_client.put_object(Body=fp.read(), Bucket=args.model_dir, Key=args.model_filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "7708f5fa-c479-4278-ac6e-8a0b0effb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model locally\n",
    "! python train.py --n-estimators 2 \\\n",
    "--min-samples-leaf 100 \\\n",
    "--model-dir \"dry-bean-classification-problem-usa-east1\" \\\n",
    "--train-dir \"s3://dry-bean-classification-problem-usa-east1/dataset/\" \\\n",
    "--test-dir  \"s3://dry-bean-classification-problem-usa-east1/dataset/\" \\\n",
    "--train-file \"dry-bean-train.csv\" \\\n",
    "--test-file \"dry-bean-test.csv\" \\\n",
    "--features \"Area Perimeter MajorAxisLength MinorAxisLength AspectRation Eccentricity ConvexArea EquivDiameter Extent Solidity roundness Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4\" \\\n",
    "--target \"Class\" \\\n",
    "--model-filename \"models/model.joblib\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d556fd-dc2f-44b5-93e6-3c70d9df0f87",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "762788b9-1443-4825-b723-68e37ba65203",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eec90f-8ad2-4764-923f-7a47c0e7a728",
   "metadata": {},
   "source": [
    "### Custom Training Job\n",
    "\n",
    "### Spot Training.\n",
    "Using the machines on demand can be very expensive. To cut down costs, Amazon offers Spot Training instances. With those instances, you can choose high-powered computing resources for a low price with a single caveat — the training won’t start immediately. Instead, SageMaker waits until the demand is low and the machine you requested is available. \n",
    "\n",
    "To enable Spot Training, you have to add only a couple of lines to the last code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "3a1dcff5-fb6a-4012-a024-ab737c44cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    #py_version=\"py311\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=\"1.2-1\", # check what version of sklearn and pyhon suported by sagemaker in pre-insntalled package / containers.\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 2,\n",
    "        \"min-samples-leaf\": 100,\n",
    "        \"max-depth\":5,\n",
    "        \"features\": \"Area Perimeter MajorAxisLength MinorAxisLength AspectRation Eccentricity ConvexArea EquivDiameter Extent Solidity roundness Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4\",\n",
    "        \"target\": \"Class\",\n",
    "        \"train-file\": \"dry-bean-train.csv\", \n",
    "        \"test-file\": \"dry-bean-test.csv\",\n",
    "        \"model-dir\": \"dry-bean-classification-problem-usa-east1\", #\"/opt/ml/output/\" # Save it in current direcrtory then we will upload it to S3 bucker\n",
    "        \"model-filename\": \"models/model.joblib\"\n",
    "    }#,\n",
    "    # Below parameters are for spot training.\n",
    "    #use_spot_instances=True,\n",
    "    #max_wait=7200,\n",
    "    #max_run=3600,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "cef900c4-8115-4935-9362-33bbd88f3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "s3_train_dir=\"s3://sagemaker-us-east-1-205930620783/dry-bean-classification-problem/dataset/\"\n",
    "sklearn_estimator.fit({'train': s3_train_dir, 'test': s3_train_dir}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "34b25aaa-cfb2-46b0-86b3-23df9fbef2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "3d5baca6-fd84-4b8f-b56a-e69a5aea52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "   \"n-estimators\": IntegerParameter(2, 10),\n",
    "   \"min-samples-leaf\": IntegerParameter(10, 30),\n",
    "}\n",
    "\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "   estimator=sklearn_estimator,\n",
    "   hyperparameter_ranges=hyperparameter_ranges,\n",
    "   base_tuning_job_name=\"RF-tuner\",\n",
    "   objective_type=\"Maximize\",\n",
    "   objective_metric_name=\"balanced-accuracy\",\n",
    "   metric_definitions=[\n",
    "       {\"Name\": \"balanced-accuracy\", \"Regex\": \"Test balanced accuracy: ([0-9.]+).*$\"} # The training script will log/print the test accuracy, and this training job will capture this, and make a decsion of best estimator using this.\n",
    "   ],  # Extract tracked metric from logs with regexp\n",
    "   max_jobs=10,\n",
    "   max_parallel_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "af53a103-e9ae-4d1c-8320-2e122acd9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "s3_train_dir=\"s3://sagemaker-us-east-1-205930620783/dry-bean-classification-problem/dataset/\"\n",
    "Optimizer.fit({'train': s3_train_dir, 'test': s3_train_dir}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "2915c194-4688-49be-9d54-d8e5e2a22643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tuner results in a df\n",
    "results = Optimizer.analytics().dataframe()\n",
    "\n",
    "while results.empty:\n",
    "   time.sleep(1)\n",
    "   results = Optimizer.analytics().dataframe()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "62a60a7b-34fe-4ac1-9386-5ec1c6637394",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = Optimizer.best_estimator()\n",
    "print(best_estimator.latest_training_job.name)\n",
    "artifact_path = sagemaker_client.describe_training_job(\n",
    "   TrainingJobName=best_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "b7ea8371-780d-40eb-a4b1-266dabe0fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "   model_data=artifact_path,\n",
    "   role=get_execution_role(),\n",
    "   entry_point=\"train.py\",\n",
    "   framework_version=\"1.2-1\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "98f1758e-100f-4e2f-acf8-38bd31955539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "sk_endpoint_name = \"sklearn-rf-model\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sk_predictor = best_estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", endpoint_name=sk_endpoint_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
