{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ed565f-b59b-42ef-a775-2664639fa09a",
   "metadata": {},
   "source": [
    "# Amazon Sagemaker AI : Dry Bean Classification Problem\n",
    "You will learn\n",
    " - Using Sagemaker AI to train the model in notebook itself.\n",
    " - AWS -> Sagemaker AI ->  Create a Domain -> Open Studio -> Creating a Jupyter Lab Space with a machine\n",
    " - In Jupyter Lab Space create a notebook -> load dataset -> and train model in notebook itself\n",
    "\n",
    "reference: https://www.datacamp.com/tutorial/aws-sagemaker-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_state": "idle",
   "id": "a0fd389b-2963-404b-84eb-1e4eb6915dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import boto3 \n",
    "import sagemaker \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_state": "idle",
   "id": "c30bc016-d250-4389-9ec4-40b0e8e2b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "arn:aws:iam::205930620783:role/service-role/AmazonSageMaker-ExecutionRole-20250401T145997\n"
     ]
    }
   ],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "REGION = sess.boto_session.region_name\n",
    "print(REGION)\n",
    "print(get_execution_role(sagemaker_session=sess))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "e37f1c15-e0e0-44b5-ac1d-ae5a7f4d74e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dry-bean-classification-problem-usa-east1\n"
     ]
    }
   ],
   "source": [
    "# Only able to read and write in the default created bucket\n",
    "#BUCKET_NAME = \"sagemaker-us-east-1-205930620783\"\n",
    "#DATASET_PREFIX = \"dry-bean-classification-problem/dataset\"\n",
    "\n",
    "BUCKET_NAME = \"dry-bean-classification-problem-usa-east1\"\n",
    "BUCKET_URI = f\"s3://{BUCKET_NAME}\"\n",
    "DATASET_PREFIX = \"dataset\"\n",
    "print(BUCKET_URI)\n",
    "DATASET_FILE = \"Dry_Bean_Dataset.csv\"\n",
    "TARGET_VAR = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "d4153ca1-178c-4893-8721-aa2326a64946",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"{BUCKET_URI}/{DATASET_PREFIX}/{DATASET_FILE}\")\n",
    "data['Class_Raw'] = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "e471f939-ac20-4ac5-86a5-66b40f61c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "DERMASON    3546\n",
      "SIRA        2636\n",
      "SEKER       2027\n",
      "HOROZ       1928\n",
      "CALI        1630\n",
      "BARBUNYA    1322\n",
      "BOMBAY       522\n",
      "Name: count, dtype: int64\n",
      "(13611,)\n",
      "0    5\n",
      "1    5\n",
      "2    5\n",
      "3    5\n",
      "4    5\n",
      "5    5\n",
      "6    5\n",
      "7    5\n",
      "8    5\n",
      "9    5\n",
      "Name: Class, dtype: int64\n",
      "Class\n",
      "3    3546\n",
      "6    2636\n",
      "5    2027\n",
      "4    1928\n",
      "2    1630\n",
      "0    1322\n",
      "1     522\n",
      "Name: count, dtype: int64\n",
      "{3: 0.2605245757108221, 6: 0.19366688707662919, 5: 0.148923664682977, 4: 0.1416501359194769, 2: 0.11975607964146646, 0: 0.09712732348835501, 1: 0.03835133348027331}\n"
     ]
    }
   ],
   "source": [
    "#print(data.info())\n",
    "print(data['Class'].value_counts())\n",
    "# Target variable is a categorical factor.\n",
    "le = preprocessing.LabelEncoder()\n",
    "data[TARGET_VAR] = le.fit_transform(data[TARGET_VAR]) # It will just map the categories to numbers in range 0, len(categories). This is an orfinal mapping i.e. so I don't think its a correect way to do that.\n",
    "print(data[TARGET_VAR].shape)\n",
    "print(data[TARGET_VAR][0:10])\n",
    "print(data[TARGET_VAR].value_counts())\n",
    "class_weights = data[TARGET_VAR].value_counts(normalize=True).to_dict()\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "ea5d1c24-e2f5-4f51-adc1-eafb866340da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10888, 17) Index([2301, 5659, 8597, 6157, 4544, 749, 9556, 6877, 8403, 9485], dtype='int64')\n",
      "(2723, 17) Index([13027, 11035, 13205, 7578, 1961, 3885, 1094, 12187, 12526, 9540], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(data.drop('Class_Raw', axis=1), test_size=.2, random_state=0)\n",
    "print(df_train.shape, df_train.index[0:10])\n",
    "print(df_test.shape, df_test.index[0:10])\n",
    "df_train.to_csv('dry-bean-train.csv')\n",
    "df_test.to_csv('dry-bean-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_state": "idle",
   "id": "833e01c3-403d-4d74-ae6e-6f0b24944608",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = sess.upload_data(\n",
    "   path=\"dry-bean-train.csv\",\n",
    "   bucket=BUCKET_NAME,\n",
    "   key_prefix=DATASET_PREFIX, # Subdir\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "   path=\"dry-bean-test.csv\",\n",
    "   bucket=BUCKET_NAME,\n",
    "   key_prefix=DATASET_PREFIX,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "execution_state": "idle",
   "id": "147c6c8e-313e-4f97-ac14-ce19f7c2ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10888, 16) (10888,) (2723, 16) (2723,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train.drop(['Class'], axis=1).values, df_train['Class'].values\n",
    "X_test, y_test = df_test.drop(['Class'], axis=1).values, df_test['Class'].values\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "execution_state": "idle",
   "id": "7fcbba8b-e609-4000-869f-d23b36bbfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators=100, min_samples_leaf=20, random_state=0, n_jobs=-1, class_weight=class_weights)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_test_pred = model_rf.predict(X_test)\n",
    "y_train_pred = model_rf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "execution_state": "idle",
   "id": "d9ea6aea-cfd6-486b-b57a-7f23610f7dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 6 5 2 5 3 3 6]\n",
      "[3 3 3 3 6 4 5 3 3 6]\n",
      "0.9234898448914083 0.9311536024911987\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0:10])\n",
    "print(y_test_pred[0:10])\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "acc_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "acc_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(acc_test, acc_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
